# âš™ï¸ Atividade 2 â€“ GerÃªncia de ConfiguraÃ§Ã£o  
**Engenharia de Software II**

Este repositÃ³rio contÃ©m todos os **artefatos, evidÃªncias, scripts, prompts, anÃ¡lises manuais e anÃ¡lises via InteligÃªncia Artificial** utilizados na **Atividade 02** da disciplina de **Engenharia de Software II**.

O foco desta etapa foi a **anÃ¡lise das estratÃ©gias de GerÃªncia de ConfiguraÃ§Ã£o** do projeto **microsoft/JARVIS (HuggingGPT)**, com Ãªnfase em:

- Modelo de fluxo de trabalho (Branching Model)
- EstratÃ©gia de releases
- Uso de branches, merges, tags e histÃ³rico de commits
- Grau de maturidade do processo de versionamento

---

## ğŸ’¡ Projeto Analisado â€” JARVIS (HuggingGPT)

O **JARVIS** Ã© um sistema baseado em **Large Language Models (LLMs)** que atua como um **orquestrador central**.  
Ele recebe uma tarefa complexa, divide em subtarefas e as delega para **LLMs especializadas**, hospedadas na plataforma **Hugging Face**, consolidando os resultados em uma resposta final.

Por se tratar de um projeto **ativo, colaborativo e de cÃ³digo aberto**, o JARVIS Ã© um excelente estudo de caso para anÃ¡lise de **fluxos de versionamento, integraÃ§Ã£o contÃ­nua e releases**.

---

## ğŸ¯ Objetivo da Atividade 2

O objetivo desta atividade foi **analisar como o projeto JARVIS gerencia sua configuraÃ§Ã£o ao longo do tempo**, respondendo principalmente Ã s seguintes questÃµes:

- Qual **modelo de branching** Ã© adotado? (GitHub Flow, Trunk-Based, Gitflow, etc.)
- Existe uma **estratÃ©gia formal de releases**?
- O projeto utiliza **versionamento semÃ¢ntico (SemVer)**?
- Qual o **nÃ­vel de maturidade** do processo de desenvolvimento?
- Como a equipe lida com **integraÃ§Ãµes, merges e contribuiÃ§Ãµes externas**?

Para isso, foram utilizadas **trÃªs abordagens complementares**:
1. **AnÃ¡lise via LLM (Hugging Face)**
2. **AnÃ¡lise Manual / Visual**
3. **AnÃ¡lise EstatÃ­stica**

---

## ğŸ‘¥ Equipe

| NÂº | Nome                                  | MatrÃ­cula       |
|----|--------------------------------------|-----------------|
| 01 | AndrÃ© Felipe de Santana ConceiÃ§Ã£o    | 202300061527    |
| 02 | David Vieira Reis                    | 202100011299    |
| 03 | Adailton Moura da Silva              | 202100011154    |
| 04 | Enzo Emanuel Maia Costa              | 202300061901    |
| 05 | Rafael Souza Prata                   | 202300061750    |
| 06 | Vinicius Morais Souza                | 202200060106    |
| 07 | Felipe Ferreira da Silva             | 202100113360    |
| 08 | JoÃ£o Filipe de AraÃºjo Santos Rezende | 202100011548    |

---

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

O repositÃ³rio estÃ¡ organizado de acordo com os **tipos de anÃ¡lise realizados na Etapa 2**.

```text
ğŸ“¦ Engenharia_SoftwareII_2025-2_T04_JARVIS_Etapa02
â”‚
â”œâ”€â”€ ğŸ“‚ AnÃ¡lise de logs e evidÃªncias via IA/
â”‚   â”œâ”€â”€ ğŸ“‚ AndrÃ© Felipe - 202300061527/
â”‚   â”œâ”€â”€ ğŸ“‚ David Vieira Reis - 202100011299/
â”‚   â”œâ”€â”€ ğŸ“‚ Rafael Souza Prata - 202300061750/
â”‚   â””â”€â”€ ğŸ“‚ Vinicius Morais Souza - 202200060106/
â”‚
â”œâ”€â”€ ğŸ“‚ AnÃ¡lise Manual/
â”‚   â”œâ”€â”€ ğŸ“‚ Adailton Moura da Silva - 202100011154/
â”‚   â”œâ”€â”€ ğŸ“‚ Enzo Emanuel - 202300061901/
â”‚   â””â”€â”€ ğŸ“‚ Felipe Ferreira - 202100113360/


â”‚
â””â”€â”€ ğŸ“„ README.md
```
Cada pasta individual contÃ©m:

- Scripts utilizados para coleta de dados  
- Logs do Git (`git log`, `git branch`, `git tag`)  
- Prompts enviados Ã s LLMs  
- Respostas das IAs  
- EvidÃªncias textuais e visuais  
- AnÃ¡lises e conclusÃµes individuais  

---

## ğŸ¤– AnÃ¡lise via LLM (Hugging Face)

A anÃ¡lise automatizada com IA teve como objetivo verificar se uma **LLM** consegue identificar corretamente:

- O **Branching Model**  
- A **EstratÃ©gia de Release**  
- EvidÃªncias tÃ©cnicas no histÃ³rico do Git  

### ğŸ”¹ Modelos Utilizados

- **Qwen/Qwen2.5-72B-Instruct**  
- **Meta-Llama-3-8B-Instruct**  
- **DeepSeek-R1**  

### ğŸ”¹ EstratÃ©gia de Fornecimento de Dados

Foram utilizados:

- `git log --graph --oneline`  
- `git branch -r`  
- `git tag`  

AlÃ©m disso, os dados foram consolidados em **arquivos `.txt`**, preparados especificamente para consumo por **LLMs**.

---

## ğŸ” AnÃ¡lise Manual / Visual

A anÃ¡lise manual foi realizada diretamente:

- Pela interface do **GitHub**  
- Pelo histÃ³rico de commits  
- Pela estrutura de branches  
- Pela observaÃ§Ã£o da frequÃªncia de merges e integraÃ§Ãµes  

Essa abordagem teve como objetivo **validar ou refutar** os resultados obtidos pelas anÃ¡lises via IA.

---

## ğŸ“Š AnÃ¡lise EstatÃ­stica

A anÃ¡lise estatÃ­stica teve como foco:

- FrequÃªncia de commits  
- AusÃªncia ou presenÃ§a de tags  
- PadrÃµes de entrega contÃ­nua  
- IdentificaÃ§Ã£o de possÃ­veis estratÃ©gias de release  
  (Continuous Delivery, Rapid Release, LTS)  

Essa anÃ¡lise complementa as abordagens anteriores, trazendo uma **visÃ£o quantitativa** do processo.

---

## ğŸ“Œ ConclusÃ£o Geral

A partir das anÃ¡lises realizadas (IA, manual e estatÃ­stica), foi possÃ­vel concluir que o projeto **JARVIS**:

- NÃ£o adota versionamento semÃ¢ntico formal (**SemVer**)  
- NÃ£o utiliza **tags de release** no Git  
- Opera majoritariamente em um fluxo **GitHub Flow / Trunk-Based**  
- Realiza integraÃ§Ãµes frequentes diretamente na branch **`main`**  
- Possui um nÃ­vel de maturidade **moderado**, com boas prÃ¡ticas de colaboraÃ§Ã£o, porÃ©m com oportunidades claras de melhoria em **automaÃ§Ã£o, versionamento e controle de releases**  

---

## â–¶ï¸ Como Executar as AnÃ¡lises por Modelo

Esta seÃ§Ã£o descreve, de forma objetiva, como cada modelo de IA foi utilizado durante a anÃ¡lise da gerÃªncia de configuraÃ§Ã£o do projeto JARVIS.

---

### ğŸŸ£ Qwen/Qwen2.5-72B-Instruct

#### âœ”ï¸ Como Executar

Para a anÃ¡lise com o modelo **Qwen**, foi utilizada uma abordagem de **extraÃ§Ã£o estruturada de dados**, automatizada por meio de um script em Python.

**Passos:**

1. Clone o repositÃ³rio do projeto JARVIS localmente:
   ```bash
   git clone https://github.com/microsoft/JARVIS.git

Execute o script Python de extraÃ§Ã£o de evidÃªncias (`script.py`), que coleta:

- Grafo de commits (`git log --graph --oneline`)
- Branches remotas (`git branch -r`)
- Tags (`git tag`)

  > ğŸ“Œ **LocalizaÃ§Ã£o do Script de ExtraÃ§Ã£o**

O arquivo `script.py`, responsÃ¡vel pela extraÃ§Ã£o de logs e evidÃªncias do repositÃ³rio, estÃ¡ localizado na seguinte estrutura de diretÃ³rios:

```text
ğŸ“¦ Engenharia_SoftwareII_2025-2_T04_JARVIS_Etapa02
â”‚
â”œâ”€â”€ ğŸ“‚ AnÃ¡lise de logs e evidÃªncias via IA/
â”‚   â”œâ”€â”€ ğŸ“‚ AndrÃ© Felipe - 202300061527/
         â”œâ”€â”€ script.py 
```

O script gera automaticamente um arquivo consolidado:

- `log_para_ia.txt`

2. Acesse o **HuggingChat (Qwen)** na plataforma **Hugging Face**.

3. Cole o prompt de anÃ¡lise junto com o conteÃºdo do arquivo `log_para_ia.txt`.

4. Analise a resposta retornada pelo modelo, focando em:

- Branching Model
- EstratÃ©gia de Releases
- EvidÃªncias tÃ©cnicas no histÃ³rico do Git

### ğŸŸ¢ Meta-Llama-3-8B-Instruct

#### âœ”ï¸ Como Executar

1. Gere manualmente os arquivos de evidÃªncia a partir do repositÃ³rio JARVIS:

```bash
git branch -a
git log --merges --oneline --all
git log main -n 50
```
2. Salve as saÃ­das em arquivos .txt.

3. Acesse a pÃ¡gina do modelo Meta-Llama-3-8B-Instruct no Hugging Face.

4. Na interface de inferÃªncia, cole:

O prompt estruturado

O conteÃºdo dos arquivos de evidÃªncia

5. Avalie o resultado com base nas evidÃªncias fornecidas, sem assumir informaÃ§Ãµes nÃ£o observÃ¡veis.

### ğŸ”µ DeepSeek-R1

#### âœ”ï¸ Como Executar

1. Gere o histÃ³rico completo de commits:

```bash
git log > log.txt
```
2. Acesse o modelo DeepSeek-R1 no Hugging Face.

3. Envie o prompt tÃ©cnico junto com o conteÃºdo completo do arquivo log.txt.

4. Solicite explicitamente que a anÃ¡lise seja baseada exclusivamente nas evidÃªncias observÃ¡veis.

5. Utilize a resposta para avaliar:

EstratÃ©gia de releases

Modelo de fluxo de trabalho

Grau de maturidade do processo

---

## ğŸ”§ Infraestrutura (Ambiente de ExecuÃ§Ã£o)

As anÃ¡lises com LLM foram realizadas utilizando exclusivamente a infraestrutura das prÃ³prias plataformas de IA, acessadas via navegador, sem execuÃ§Ã£o em ambientes de notebook ou *cloud compute* gerenciados pelo grupo.

---

### â˜ï¸ Ambiente de Nuvem â€” Interface Nativa das LLMs

A execuÃ§Ã£o ocorreu diretamente nas interfaces web das LLMs, que disponibilizam inferÃªncia imediata a partir da inserÃ§Ã£o de prompts.

**Infraestrutura adotada (padrÃ£o da plataforma):**

- **Plataforma:** Hugging Face / HuggingChat  
- **ExecuÃ§Ã£o:** Interface Web (Chat / Inference)  
- **Processamento:** Infraestrutura gerenciada pelo provedor da LLM  
- **GPU / CPU:** Gerenciada internamente pela plataforma  
- **RAM e Disco:** NÃ£o expostos ao usuÃ¡rio  
- **ConfiguraÃ§Ã£o local:** NÃ£o necessÃ¡ria  

Esse ambiente foi utilizado para:

- Qwen/Qwen2.5-72B-Instruct  
- Meta-Llama-3-8B-Instruct  
- DeepSeek-R1  


## ğŸ“š RelatÃ³rio e Material Complementar

- ğŸ“„ **RelatÃ³rio Completo (PDF â€“ Etapa 2):**  
  [Acesse aqui](https://docs.google.com/document/d/1LzsOySSWbhy81r3u3X7ldHWZYF_D6ev-isXvMyRwxqQ/edit?pli=1&tab=t.0#heading=h.35j97j8nvhs5).

- ğŸ¥ **VÃ­deo do Grupo:**  
  [Acesse aqui](https://drive.google.com/file/d/1nwgLRhP7H86so4XC7LhvmYyNlCcLmOYX/view?usp=drive_link).


